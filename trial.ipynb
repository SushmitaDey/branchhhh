{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sushmitad\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log10\n",
      "c:\\users\\sushmitad\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in float_scalars\n",
      "c:\\users\\sushmitad\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\librosa\\core\\pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=0, tol=0.0001, verbose=0)\n",
      "[0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "TIME : 0.0 ---- SPEAKER : 0\n",
      "TIME : 4.4 ---- SPEAKER : 1\n",
      "TIME : 4.8 ---- SPEAKER : 0\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/bmonikraj/speaker-diarization-py\n",
    "import librosa as li\n",
    "import numpy as np \n",
    "from sklearn.cluster import AffinityPropagation, KMeans\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "file_name = \"playback2.wav\"\n",
    "audio_time_series, sample_rate = li.load(file_name)\n",
    "length_series = len(audio_time_series)\n",
    "print(length_series)\n",
    "\n",
    "zero_crossings = []\n",
    "energy = []\n",
    "entropy_of_energy = []\n",
    "mfcc = []\n",
    "chroma_stft = []\n",
    "for i in range(0,length_series,int(sample_rate/5.0)):\n",
    "     frame_self = audio_time_series[i:i+int(sample_rate/5.0):1]\n",
    "     z = li.zero_crossings(frame_self)\n",
    "     arr = np.nonzero(z)\n",
    "     zero_crossings.append(len(arr[0]))\n",
    "     e = li.feature.rmse(frame_self)\n",
    "     energy.append(np.mean(e))\n",
    "     ent = 0.0\n",
    "     m = np.mean(e)\n",
    "     for j in range(0,len(e[0])):\n",
    "          q = np.absolute(e[0][j] - m)\n",
    "          ent = ent + (q * np.log10(q))\n",
    "     entropy_of_energy.append(ent)\n",
    "     mt = []\n",
    "     mf = li.feature.mfcc(frame_self)\n",
    "     for k in range(0,len(mf)):\n",
    "          mt.append(np.mean(mf[k]))\n",
    "     mfcc.append(mt)\n",
    "     ct = []\n",
    "     cf = li.feature.chroma_stft(frame_self)\n",
    "     for k in range(0,len(cf)):\n",
    "          ct.append(np.mean(cf[k]))\n",
    "     chroma_stft.append(ct)\n",
    "#      print(i)\n",
    "f_list_1 = []\n",
    "f_list_1.append(zero_crossings)\n",
    "f_list_1.append(energy)\n",
    "f_list_1.append(entropy_of_energy)\n",
    "f_np_1 = np.array(f_list_1)\n",
    "f_np_1 = np.transpose(f_np_1)\n",
    "\n",
    "sp_centroid = []\n",
    "sp_bandwidth = []\n",
    "sp_contrast = []\n",
    "sp_rolloff = []\n",
    "for i in range(0,length_series,int(sample_rate/5.0)):\n",
    "     frame_self = audio_time_series[i:i+int(sample_rate/5.0):1]\n",
    "     cp = li.feature.spectral_centroid(y=frame_self, hop_length=220500)\n",
    "     sp_centroid.append(cp[0][0])\n",
    "     bp = li.feature.spectral_bandwidth(y=frame_self, hop_length=220500)\n",
    "     sp_bandwidth.append(bp[0][0])\n",
    "     csp = li.feature.spectral_contrast(y=frame_self, hop_length=220500)\n",
    "     sp_contrast.append(np.mean(csp))\n",
    "     rsp = li.feature.spectral_rolloff(y=frame_self, hop_length=220500)\n",
    "     sp_rolloff.append(np.mean(rsp[0][0]))\n",
    "#      print(i)\n",
    "\n",
    "f_list_2 = []\n",
    "f_list_2.append(sp_centroid)\n",
    "f_list_2.append(sp_bandwidth)\n",
    "f_list_2.append(sp_contrast)\n",
    "f_list_2.append(sp_rolloff)\n",
    "f_np_2 = np.array(f_list_2)\n",
    "f_np_2 = np.transpose(f_np_2)\n",
    "\n",
    "f_np_3 = np.array(mfcc)\n",
    "f_np_4 = np.array(chroma_stft)\n",
    "\n",
    "master = np.concatenate([f_np_1, f_np_2, f_np_3, f_np_4], axis=1)\n",
    "df1=pd.DataFrame(master)\n",
    "master[23,2]=np.mean(df1[2])\n",
    "\n",
    "# i=1\n",
    "#print(np.mean(df1[2]))\n",
    "# df1.iloc[23,2]=np.mean(df1[2])\n",
    "# print(df1.iloc[23,2])\n",
    "#print(df1.isna())\n",
    "#cluster_obj = AffinityPropagation().fit(master)\n",
    "cluster_obj = KMeans(n_clusters = 2 ,random_state=0).fit(master)\n",
    "\n",
    "print(cluster_obj)\n",
    "#print(\"Number of clusters : \" + str(len(cluster_obj.cluster_centers_indices_)))\n",
    "res = cluster_obj.predict(master)\n",
    "#print(cluster_obj.get_params())\n",
    "print(res)\n",
    "s = res[0]\n",
    "t=0.0\n",
    "time = []\n",
    "speaker = []\n",
    "time.append(t)\n",
    "speaker.append(s)\n",
    "\n",
    "for u in range(0, len(res), 1):\n",
    "     if(res[u]==s):\n",
    "          t=t+0.2\n",
    "     else:\n",
    "          t=t+0.2\n",
    "          s=res[u]\n",
    "          speaker.append(s)\n",
    "          time.append(t)\n",
    "\n",
    "# print(time)\n",
    "# print(speaker)\n",
    "speakerN = speaker\n",
    "speakerN.append(0)\n",
    "for i in range(2, len(time)):\n",
    "     if((time[i]-time[i-1]) < 0.75):\n",
    "          pass\n",
    "     else:\n",
    "          speaker[i-1] = speakerN[i-2]     \n",
    "\n",
    "fin = []\n",
    "for i in range(1,len(time)):\n",
    "     if(speaker[i]!=speaker[i-1]):\n",
    "          fin.append([time[i-1], speaker[i-1]])\n",
    "     else:\n",
    "          pass\n",
    "# print(len(fin))\n",
    "for p in range(0, len(fin)):\n",
    "    print(\"TIME : \" + str(round(fin[p][0],2)) + \" ---- \" + \"SPEAKER : \" + str(fin[p][1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14355095080389985"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master[23,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
